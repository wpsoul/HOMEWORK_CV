{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results of each tracking are in video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/tensorflow/ssd-mobilenet-v2/tensorFlow2/fpnlite-320x320/1/download/variables/variables.index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/tensorflow/ssd-mobilenet-v2/tensorFlow2/fpnlite-320x320/1/download/variables/variables.data-00000-of-00001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/6.74k [00:00<?, ?B/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/tensorflow/ssd-mobilenet-v2/tensorFlow2/fpnlite-320x320/1/download/saved_model.pb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.74k/6.74k [00:00<00:00, 764kB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 8.83M/8.83M [00:06<00:00, 1.40MB/s]\n",
      "\n",
      "\u001b[A\n",
      "100%|██████████| 10.3M/10.3M [00:06<00:00, 1.55MB/s]\n",
      "Downloading 3 files: 100%|██████████| 3/3 [00:08<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to model files: /Users/home/.cache/kagglehub/models/tensorflow/ssd-mobilenet-v2/tensorFlow2/fpnlite-320x320/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.model_download(\"tensorflow/ssd-mobilenet-v2/tensorFlow2/fpnlite-320x320\")\n",
    "print(\"Path to model files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 18:41:40.197979: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "sh: python: command not found\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "\n",
    "def list_connected_devices(max_devices=10):\n",
    "    available_devices = []\n",
    "    for device_index in range(max_devices):\n",
    "        cap = cv2.VideoCapture(device_index)\n",
    "        if cap.isOpened():\n",
    "            available_devices.append(device_index)\n",
    "            cap.release()\n",
    "    return available_devices\n",
    "#print(\"Connected video devices:\", list_connected_devices())\n",
    "\n",
    "# Load pre-trained MobileNet-SSD model\n",
    "model = tf.saved_model.load(\"saved_model\")\n",
    "\n",
    "# Function to perform human detection and distance estimation\n",
    "def detect_and_estimate_distance(frame, threshold_area):\n",
    "    input_tensor = tf.convert_to_tensor(frame)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    \n",
    "    detections = model(input_tensor)\n",
    "\n",
    "    boxes = detections['detection_boxes'][0].numpy()\n",
    "    classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "    scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] > 0.5 and classes[i] == 1:  # Class 1 corresponds to 'person'\n",
    "            ymin, xmin, ymax, xmax = boxes[i]\n",
    "            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width, ymin * frame_height, ymax * frame_height)\n",
    "            area = (right - left) * (bottom - top)\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n",
    "            \n",
    "            # Check if area exceeds threshold\n",
    "            if area > threshold_area:\n",
    "                return True, frame\n",
    "    \n",
    "    return False, frame\n",
    "\n",
    "# Access webcam and process frames\n",
    "cap = cv2.VideoCapture(0)\n",
    "threshold_area = 50000  # Define an appropriate threshold area\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    is_close, processed_frame = detect_and_estimate_distance(frame, threshold_area)\n",
    "\n",
    "    if is_close:\n",
    "        # Run drone.py\n",
    "        cv2.imshow(\"Frame\", processed_frame)\n",
    "        os.system('python drone.py')\n",
    "        # Pause execution for 1 minute\n",
    "        time.sleep(60)\n",
    "        break\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
